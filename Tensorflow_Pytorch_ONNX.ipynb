{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd022f78e36578c4ff23c173c4007cccb24924bfcbe17be6a7fce06badcb0d73267",
   "display_name": "Python 3.8.0 64-bit ('dl': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Pytorch\n",
    "\n",
    "It is easy to export a Pytorch model to ONNX because it is built into the API. The Pytorch documentation provides a good example on how to perform this conversion.\n",
    "\n",
    "This is a simplified example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1,3,224,224, device='cpu')\n",
    "model = torchvision.models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = ['input_alexnet'] + ['layer_%d' % i for i in range(16)]\n",
    "output_name = ['output_alexnet'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "graph(%input_alexnet : Float(10, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n      %layer_0 : Float(64, 3, 11, 11, strides=[363, 121, 11, 1], requires_grad=1, device=cpu),\n      %layer_1 : Float(64, strides=[1], requires_grad=1, device=cpu),\n      %layer_2 : Float(192, 64, 5, 5, strides=[1600, 25, 5, 1], requires_grad=1, device=cpu),\n      %layer_3 : Float(192, strides=[1], requires_grad=1, device=cpu),\n      %layer_4 : Float(384, 192, 3, 3, strides=[1728, 9, 3, 1], requires_grad=1, device=cpu),\n      %layer_5 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %layer_6 : Float(256, 384, 3, 3, strides=[3456, 9, 3, 1], requires_grad=1, device=cpu),\n      %layer_7 : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %layer_8 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n      %layer_9 : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %layer_10 : Float(4096, 9216, strides=[9216, 1], requires_grad=1, device=cpu),\n      %layer_11 : Float(4096, strides=[1], requires_grad=1, device=cpu),\n      %layer_12 : Float(4096, 4096, strides=[4096, 1], requires_grad=1, device=cpu),\n      %layer_13 : Float(4096, strides=[1], requires_grad=1, device=cpu),\n      %layer_14 : Float(1000, 4096, strides=[4096, 1], requires_grad=1, device=cpu),\n      %layer_15 : Float(1000, strides=[1], requires_grad=1, device=cpu)):\n  %17 : Float(10, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%input_alexnet, %layer_0, %layer_1) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:395:0\n  %18 : Float(10, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Relu(%17) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %19 : Float(10, 64, 27, 27, strides=[46656, 729, 27, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%18) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:659:0\n  %20 : Float(10, 192, 27, 27, strides=[139968, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%19, %layer_2, %layer_3) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:395:0\n  %21 : Float(10, 192, 27, 27, strides=[139968, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Relu(%20) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %22 : Float(10, 192, 13, 13, strides=[32448, 169, 13, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%21) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:659:0\n  %23 : Float(10, 384, 13, 13, strides=[64896, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%22, %layer_4, %layer_5) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:395:0\n  %24 : Float(10, 384, 13, 13, strides=[64896, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%23) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %25 : Float(10, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%24, %layer_6, %layer_7) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:395:0\n  %26 : Float(10, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%25) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %27 : Float(10, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%26, %layer_8, %layer_9) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:395:0\n  %28 : Float(10, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%27) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %29 : Float(10, 256, 6, 6, strides=[9216, 36, 6, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%28) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:659:0\n  %30 : Float(10, 256, 6, 6, strides=[9216, 36, 6, 1], requires_grad=1, device=cpu) = onnx::AveragePool[kernel_shape=[1, 1], strides=[1, 1]](%29) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1037:0\n  %31 : Float(10, 9216, strides=[9216, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1](%30) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n  %32 : Float(10, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%31, %layer_10, %layer_11) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %33 : Float(10, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Relu(%32) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n  %34 : Float(10, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%33, %layer_12, %layer_13) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %35 : Float(10, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Relu(%34) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %output_alexnet : Float(10, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%35, %layer_14, %layer_15) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  return (%output_alexnet)\n\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, dummy_input, 'alexnet_onnx.onnx', verbose=True, input_names= input_names, output_names=output_name)"
   ]
  },
  {
   "source": [
    "# TensorFlow\n",
    "\n",
    "Exporting a TensorFlow neural network to ONNX takes a bit longer than with Pytorch, but it is still straightforward. \n",
    "\n",
    "Tensorflow and ONNX both define their own graph format to represent to model. You can use tensorflow-onnx to export a Tensorflow model to ONNX.\n",
    "\n",
    "> Procedures to convert tensorflow model\n",
    "\n",
    ">   - get tensorflow model\n",
    ">    - convert to ONNX\n",
    ">    - validate\n",
    "\n",
    "Tensorflow uses several file formats to represent a model, such as checkpoint files, graph with weight(called frozen graph next) and saved_model, and it has APIs to generate these files. And tensorflow-onnx can accept all the three formats to represent a Tensorflow model, the format \"saved_model\" should be the preference since it doesn't require the user to specify input and output names of graph.\n",
    "\n",
    "*Resources:*\n",
    "https://github.com/onnx/tutorials"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "\n",
    "x = np.random.randn(1,224,224,3).astype(np.float32)\n",
    "x = preprocess_input(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Keras Predicted: [('n03782006', 'monitor', 0.09025134), ('n04404412', 'television', 0.08011744), ('n04286575', 'spotlight', 0.049681667)]\n",
      "INFO:tensorflow:Assets written to: resnet_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights='imagenet')\n",
    "preds = model.predict(x)\n",
    "print('Keras Predicted:', decode_predictions(preds, top=3)[0])\n",
    "model.save('resnet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\tf2onnx\\tf_loader.py:557: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    }
   ],
   "source": [
    "import tf2onnx\n",
    "import onnxruntime as rt\n",
    "\n",
    "spec = (tf.TensorSpec((None, 224, 224, 3), tf.float32, name=\"input\"),)\n",
    "output_path = \"resnet_model.onnx\"\n",
    "\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13, output_path=output_path)\n",
    "output_names = [n.name for n in model_proto.graph.output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ONNX Predicted: [('n03782006', 'monitor', 0.09025135), ('n04404412', 'television', 0.08011768), ('n04286575', 'spotlight', 0.04968174)]\n"
     ]
    }
   ],
   "source": [
    "providers = ['CPUExecutionProvider']\n",
    "m = rt.InferenceSession(output_path, providers=providers)\n",
    "onnx_pred = m.run(output_names, {\"input\": x})\n",
    "\n",
    "print('ONNX Predicted:', decode_predictions(onnx_pred[0], top=3)[0])\n",
    "\n",
    "# make sure ONNX and keras have the same results\n",
    "np.testing.assert_allclose(preds, onnx_pred[0], rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m tf2onnx.convert --opset 13 --saved-model {\"resnet_model\"} --output  {\"resnet_model.onnx\"}"
   ]
  }
 ]
}