{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd022f78e36578c4ff23c173c4007cccb24924bfcbe17be6a7fce06badcb0d73267",
   "display_name": "Python 3.8.0 64-bit ('dl': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Pytorch\n",
    "\n",
    "It is easy to export a Pytorch model to ONNX because it is built into the API. The Pytorch documentation provides a good example on how to perform this conversion.\n",
    "\n",
    "This is a simplified example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1,3,224,224, device='cpu')\n",
    "model = torchvision.models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = ['input_alexnet'] + ['layer_%d' % i for i in range(16)]\n",
    "output_name = ['output_alexnet'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "graph(%input_alexnet : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n      %layer_0 : Float(64, 3, 11, 11, strides=[363, 121, 11, 1], requires_grad=1, device=cpu),\n      %layer_1 : Float(64, strides=[1], requires_grad=1, device=cpu),\n      %layer_2 : Float(192, 64, 5, 5, strides=[1600, 25, 5, 1], requires_grad=1, device=cpu),\n      %layer_3 : Float(192, strides=[1], requires_grad=1, device=cpu),\n      %layer_4 : Float(384, 192, 3, 3, strides=[1728, 9, 3, 1], requires_grad=1, device=cpu),\n      %layer_5 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %layer_6 : Float(256, 384, 3, 3, strides=[3456, 9, 3, 1], requires_grad=1, device=cpu),\n      %layer_7 : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %layer_8 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n      %layer_9 : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %layer_10 : Float(4096, 9216, strides=[9216, 1], requires_grad=1, device=cpu),\n      %layer_11 : Float(4096, strides=[1], requires_grad=1, device=cpu),\n      %layer_12 : Float(4096, 4096, strides=[4096, 1], requires_grad=1, device=cpu),\n      %layer_13 : Float(4096, strides=[1], requires_grad=1, device=cpu),\n      %layer_14 : Float(1000, 4096, strides=[4096, 1], requires_grad=1, device=cpu),\n      %layer_15 : Float(1000, strides=[1], requires_grad=1, device=cpu)):\n  %17 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%input_alexnet, %layer_0, %layer_1) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:395:0\n  %18 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Relu(%17) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %19 : Float(1, 64, 27, 27, strides=[46656, 729, 27, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%18) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:659:0\n  %20 : Float(1, 192, 27, 27, strides=[139968, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%19, %layer_2, %layer_3) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:395:0\n  %21 : Float(1, 192, 27, 27, strides=[139968, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Relu(%20) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %22 : Float(1, 192, 13, 13, strides=[32448, 169, 13, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%21) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:659:0\n  %23 : Float(1, 384, 13, 13, strides=[64896, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%22, %layer_4, %layer_5) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:395:0\n  %24 : Float(1, 384, 13, 13, strides=[64896, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%23) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %25 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%24, %layer_6, %layer_7) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:395:0\n  %26 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%25) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %27 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%26, %layer_8, %layer_9) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:395:0\n  %28 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%27) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %29 : Float(1, 256, 6, 6, strides=[9216, 36, 6, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%28) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:659:0\n  %30 : Float(1, 256, 6, 6, strides=[9216, 36, 6, 1], requires_grad=1, device=cpu) = onnx::AveragePool[kernel_shape=[1, 1], strides=[1, 1]](%29) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1037:0\n  %31 : Float(1, 9216, strides=[9216, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1](%30) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n  %32 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%31, %layer_10, %layer_11) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %33 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Relu(%32) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n  %34 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%33, %layer_12, %layer_13) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %35 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Relu(%34) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %output_alexnet : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%35, %layer_14, %layer_15) # C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  return (%output_alexnet)\n\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, dummy_input, 'alexnet_onnx.onnx', verbose=True, input_names= input_names, output_names=output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LSTM(\n  (lstm1): LSTM(100, 128, dropout=0.3)\n  (lstm2): LSTM(128, 256, dropout=0.4)\n  (fc1): Linear(in_features=256, out_features=100, bias=True)\n  (drop1): Dropout(p=0.0, inplace=False)\n)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, in_ts, in_ch, out_dim, p=0.0):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(in_ts,  128, 1, dropout=0.3)\n",
    "        self.lstm2 = nn.LSTM(128, 256, 1, dropout=0.4)\n",
    "        self.fc1   = nn.Linear(in_ch*256, out_dim)\n",
    "        self.drop1 = nn.Dropout(p=p//2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.lstm1(x)[0])\n",
    "        x = F.tanh(self.lstm2(x)[0])\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.drop1(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "MODEL_LSTM = LSTM(100,1,100)\n",
    "print(MODEL_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\nC:\\Users\\lospa\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:1932: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n  warnings.warn(\"Exporting a model to ONNX with a batch_size other than 1, \" +\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1,1,100, device='cpu')\n",
    "torch.onnx.export(MODEL_LSTM, dummy_input, 'lstm_onnx.onnx')"
   ]
  },
  {
   "source": [
    "# TensorFlow\n",
    "\n",
    "Exporting a TensorFlow neural network to ONNX takes a bit longer than with Pytorch, but it is still straightforward. \n",
    "\n",
    "Tensorflow and ONNX both define their own graph format to represent to model. You can use tensorflow-onnx to export a Tensorflow model to ONNX.\n",
    "\n",
    "> Procedures to convert tensorflow model\n",
    "\n",
    ">   - get tensorflow model\n",
    ">    - convert to ONNX\n",
    ">    - validate\n",
    "\n",
    "Tensorflow uses several file formats to represent a model, such as checkpoint files, graph with weight(called frozen graph next) and saved_model, and it has APIs to generate these files. And tensorflow-onnx can accept all the three formats to represent a Tensorflow model, the format \"saved_model\" should be the preference since it doesn't require the user to specify input and output names of graph.\n",
    "\n",
    "*Resources:*\n",
    "https://github.com/onnx/tutorials"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "\n",
    "x = np.random.randn(1,224,224,3).astype(np.float32)\n",
    "x = preprocess_input(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Keras Predicted: [('n04404412', 'television', 0.07654696), ('n03782006', 'monitor', 0.07245921), ('n04286575', 'spotlight', 0.053543683)]\n",
      "INFO:tensorflow:Assets written to: resnet_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights='imagenet')\n",
    "preds = model.predict(x)\n",
    "print('Keras Predicted:', decode_predictions(preds, top=3)[0])\n",
    "model.save('resnet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "import onnxruntime as rt\n",
    "\n",
    "spec = (tf.TensorSpec((None, 224, 224, 3), tf.float32, name=\"input\"),)\n",
    "output_path = \"resnet_model.onnx\"\n",
    "\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13, output_path=output_path)\n",
    "output_names = [n.name for n in model_proto.graph.output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ONNX Predicted: [('n04404412', 'television', 0.07654693), ('n03782006', 'monitor', 0.07245866), ('n04286575', 'spotlight', 0.053543683)]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-05, atol=0\n\nMismatched elements: 7 / 1000 (0.7%)\nMax absolute difference: 5.5134296e-07\nMax relative difference: 1.302095e-05\n x: array([[3.322915e-05, 4.303578e-04, 1.908984e-04, 1.436556e-04,\n        2.868907e-04, 5.629365e-05, 1.296373e-04, 2.399527e-04,\n        5.998426e-05, 1.996869e-04, 1.583722e-04, 2.685153e-04,...\n y: array([[3.322940e-05, 4.303595e-04, 1.909006e-04, 1.436563e-04,\n        2.868932e-04, 5.629393e-05, 1.296389e-04, 2.399538e-04,\n        5.998453e-05, 1.996882e-04, 1.583732e-04, 2.685163e-04,...",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e270d0a8d67a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# make sure ONNX and keras have the same results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monnx_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[1;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[0;32m    838\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-05, atol=0\n\nMismatched elements: 7 / 1000 (0.7%)\nMax absolute difference: 5.5134296e-07\nMax relative difference: 1.302095e-05\n x: array([[3.322915e-05, 4.303578e-04, 1.908984e-04, 1.436556e-04,\n        2.868907e-04, 5.629365e-05, 1.296373e-04, 2.399527e-04,\n        5.998426e-05, 1.996869e-04, 1.583722e-04, 2.685153e-04,...\n y: array([[3.322940e-05, 4.303595e-04, 1.909006e-04, 1.436563e-04,\n        2.868932e-04, 5.629393e-05, 1.296389e-04, 2.399538e-04,\n        5.998453e-05, 1.996882e-04, 1.583732e-04, 2.685163e-04,..."
     ]
    }
   ],
   "source": [
    "providers = ['CPUExecutionProvider']\n",
    "m = rt.InferenceSession(output_path, providers=providers)\n",
    "onnx_pred = m.run(output_names, {\"input\": x})\n",
    "\n",
    "print('ONNX Predicted:', decode_predictions(onnx_pred[0], top=3)[0])\n",
    "\n",
    "# make sure ONNX and keras have the same results\n",
    "np.testing.assert_allclose(preds, onnx_pred[0], rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m tf2onnx.convert --opset 13 --saved-model {\"resnet_model\"} --output  {\"resnet_model.onnx\"}"
   ]
  }
 ]
}